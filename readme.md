# Ollama entity recognition benchmarks framework


### Purpose

This repository contains the code and data for the Ollama entity recognition benchmarks. The benchmarks are designed to evaluate the performance of local runnable large language models on different entity types.  This is a fun bit of code just to see which LLM could A) Be quick B) Be accurate.

The original blog post was hosted on the [Datasignal Blog](https://datasignal.uk/blog/ner.html)

### Roadmap

* Initial basic post 
* (coming next) json level configuration - you can setup tests and models just by editing a json file

### Installation

1.  Install ollama and download models you think would suit your needs
2. The code checks all installed models
3. Create env and pip install prettytable and ollama
4. Run code
5. Profit

### Feedback and contact

If you are interested, email me (chris McCabe) at info@datasignal.uk
Or on twitter https://x.com/chris_mc_cabe

[DataSignal](https://datasignal.uk) 
